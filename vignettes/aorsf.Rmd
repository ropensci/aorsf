---
title: "Introduction to aorsf"
description: >
  Learn how to get started with the basics of aorsf.
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to aorsf}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.height = 5, 
  fig.width = 7
)
```


This article covers core features of the `aorsf` package.

## Background

The oblique random forest (RF) is an extension of the traditional (axis-based) RF. Instead of using a single variable to split data and grow new branches, trees in the oblique RF use a weighted combination of multiple variables.  

## Oblique RFs for survival, classification, and regression

The purpose of `aorsf` ('a' is short for accelerated) is to provide a unifying framework to fit oblique RFs that can scale adequately to large data sets. The fastest algorithms available in the package are used by default because they often have equivalent prediction accuracy to more computational approaches.

Everything in `aorsf` begins with the `orsf()` function. Here we begin with an oblique RF for survival using the `pbc_orsf` data. Note that `n_tree` is 5 for convenience in these examples, but should be >= 500 in practice.

```{r}

library(aorsf)

# An oblique survival RF
pbc_fit <- orsf(data = pbc_orsf, 
                 n_tree = 5,
                 formula = Surv(time, status) ~ . - id)

pbc_fit

```

Next, an oblique RF for classification using the `penguins_orsf` data:

```{r}

# An oblique classification RF
penguin_fit <- orsf(data = penguins_orsf,
                    n_tree = 5, 
                    formula = species ~ .)

penguin_fit

```

and for regression, we use the `mtcars` data:

```{r}

data("mtcars")

# An oblique regression RF
cars_fit <- orsf(data = mtcars, 
                 n_tree = 5, 
                 formula = mpg ~ .)

cars_fit

```

you may notice that the first input of `aorsf` is `data`. This is a design choice that makes it easier to use `orsf` with pipes (i.e., `%>%` or `|>`). For instance,

```{r, eval=FALSE}

library(dplyr)

pbc_fit <- pbc_orsf |> 
 select(-id) |> 
 orsf(formula = Surv(time, status) ~ .,
      n_tree = 5)

```

## Interpretation

`aorsf` includes several functions dedicated to interpretation of ORSFs, both through estimation of partial dependence and variable importance.

### Variable importance

There are multiple methods to compute variable importance. 

- To compute *negation* importance, ORSF multiplies each coefficient of that variable by -1 and then re-computes the out-of-sample (sometimes referred to as out-of-bag) accuracy of the ORSF model. 

    ```{r}

    orsf_vi_negate(pbc_fit)

    ```

- You can also compute variable importance using *permutation*, a more classical approach that noises up a predictor and then assigned the resulting degradation in prediction accuracy to be the importance of that predictor.

    ```{r}
  
    orsf_vi_permute(pbc_fit)
  
    ```

- A faster alternative to permutation and negation importance is ANOVA importance, which computes the proportion of times each variable obtains a low p-value (p < 0.01) while the forest is grown.

    ```{r}
    
    orsf_vi_anova(pbc_fit)
    
    ```

### Partial dependence (PD) 

`r aorsf:::roxy_pd_explain()`

For more on PD, see the [vignette](https://docs.ropensci.org/aorsf/articles/pd.html)

### Individual conditional expectations (ICE)

`r aorsf:::roxy_ice_explain()`

For more on ICE, see the [vignette](https://docs.ropensci.org/aorsf/articles/pd.html#individual-conditional-expectations-ice)


## What about the original ORSF?

The original ORSF (i.e., `obliqueRSF`) used `glmnet` to find linear combinations of inputs. `aorsf` allows users to implement this approach using the `orsf_control_survival(method = 'net')` function: 

```{r, eval=FALSE}

orsf_net <- orsf(data = pbc_orsf, 
                 formula = Surv(time, status) ~ . - id, 
                 control = orsf_control_survival(method = 'net'))

```

`net` forests fit a lot faster than the original ORSF function in `obliqueRSF`. However, `net` forests are still much slower than `cph` ones.


## aorsf and other machine learning software

The unique feature of `aorsf` is its fast algorithms to fit ORSF ensembles. `RLT` and `obliqueRSF` both fit oblique random survival forests, but `aorsf` does so faster. `ranger` and `randomForestSRC` fit survival forests, but neither package supports oblique splitting. `obliqueRF` fits oblique random forests for classification and regression, but not survival. `PPforest` fits oblique random forests for classification but not survival. 

Note: The default prediction behavior for `aorsf` models is to produce predicted risk at a specific prediction horizon, which is not the default for `ranger`  or `randomForestSRC`. I think this will change in the future, as computing time independent predictions with `aorsf` could be helpful.

## Learning more

`aorsf` began as a dedicated package for oblique random survival forests, and so most papers published so far have focused on survival analysis and risk prediction. However, the routines for regression and classification oblique RFs in `aorsf` have high overlap with the survival ones.

- See [orsf](https://docs.ropensci.org/aorsf/reference/orsf.html) for more details on oblique random survival forests.

- see the [JCGS](https://doi.org/10.1080/10618600.2023.2231048) paper for more details on algorithms used specifically by `aorsf`.
